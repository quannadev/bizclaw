# âš¡ BizClaw

> **Fast, modular AI assistant infrastructure â€” written in pure Rust.**

BizClaw is a trait-driven AI agent platform designed to run **anywhere** â€” from Raspberry Pi to cloud servers. It supports multiple LLM providers, communication channels, and tools through a unified, swappable architecture.

[![Rust](https://img.shields.io/badge/Rust-100%25-orange?logo=rust)](https://www.rust-lang.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

---

## ğŸ¯ Features

- **ğŸ§  Local Brain Engine** â€” Run LLaMA-family models locally via GGUF format with mmap, quantization (Q4_0/Q8_0), and SIMD acceleration
- **ğŸ”Œ Multi-Provider** â€” OpenAI, Anthropic Claude, Ollama, llama.cpp, OpenRouter, or any OpenAI-compatible server
- **ğŸ’¬ Multi-Channel** â€” CLI, Zalo (Personal + OA), Telegram, Discord, WhatsApp, Webhooks
- **ğŸ› ï¸ Tool Calling** â€” Shell execution, file operations, with extensible tool registry
- **ğŸ”’ Security** â€” Command allowlists, path restrictions, sandboxed execution, encrypted secrets
- **ğŸ’¾ Memory** â€” SQLite persistence, in-memory vector search (cosine similarity), no-op mode
- **ğŸŒ HTTP Gateway** â€” Axum-based REST API with CORS and tracing middleware
- **ğŸ“¦ Modular** â€” 10 independent crates, swap any component via traits

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    bizclaw (CLI)                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚              â”‚   bizclaw-agent     â”‚                  â”‚
â”‚              â”‚  (orchestration)    â”‚                  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â–¼               â–¼               â–¼                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚ â”‚Providersâ”‚  â”‚ Channels â”‚  â”‚   Tools      â”‚         â”‚
â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚         â”‚
â”‚ â”‚ OpenAI  â”‚  â”‚   CLI    â”‚  â”‚   Shell      â”‚         â”‚
â”‚ â”‚Anthropicâ”‚  â”‚   Zalo   â”‚  â”‚   File       â”‚         â”‚
â”‚ â”‚ Ollama  â”‚  â”‚ Telegram â”‚  â”‚  (custom)    â”‚         â”‚
â”‚ â”‚LlamaCpp â”‚  â”‚ Discord  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚ â”‚  Brain  â”‚  â”‚ Webhook  â”‚                            â”‚
â”‚ â”‚ Custom  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚     â–¼               â–¼               â–¼                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚ â”‚ Memory  â”‚  â”‚ Security â”‚  â”‚   Gateway    â”‚        â”‚
â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚        â”‚
â”‚ â”‚ SQLite  â”‚  â”‚Allowlist â”‚  â”‚  Axum HTTP   â”‚        â”‚
â”‚ â”‚ Vector  â”‚  â”‚ Sandbox  â”‚  â”‚  REST API    â”‚        â”‚
â”‚ â”‚  NoOp   â”‚  â”‚ Secrets  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                    â–¼                                  â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚           â”‚ bizclaw-brainâ”‚                           â”‚
â”‚           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                           â”‚
â”‚           â”‚ GGUF Parser  â”‚                           â”‚
â”‚           â”‚ BPE Tokenizerâ”‚                           â”‚
â”‚           â”‚ Attention    â”‚                           â”‚
â”‚           â”‚ KV Cache     â”‚                           â”‚
â”‚           â”‚ Quantization â”‚                           â”‚
â”‚           â”‚ SIMD/Rayon   â”‚                           â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Crate Map

| Crate | Description | Status |
|-------|-------------|--------|
| `bizclaw-core` | Traits, types, config, errors | âœ… Complete |
| `bizclaw-brain` | Local GGUF inference engine | âœ… Foundation |
| `bizclaw-providers` | OpenAI, Anthropic, Ollama, LlamaCpp, Custom | âœ… Complete |
| `bizclaw-channels` | CLI, Zalo, Telegram, Discord | ğŸŸ¡ CLI done |
| `bizclaw-memory` | SQLite, Vector, NoOp backends | âœ… Complete |
| `bizclaw-tools` | Shell, File tools + registry | âœ… Complete |
| `bizclaw-security` | Allowlist, Sandbox, Secrets | âœ… Complete |
| `bizclaw-agent` | Agent loop, context, tool execution | âœ… Complete |
| `bizclaw-gateway` | Axum HTTP REST API | âœ… Complete |
| `bizclaw-runtime` | Native process adapter | âœ… Complete |

---

## ğŸš€ Quick Start

### Prerequisites

- **Rust** 1.85+ (edition 2024)
- **Git**

### Build

```bash
git clone https://github.com/nguyenduchoai/bizclaw.git
cd bizclaw
cargo build --release
```

### Run (CLI mode with OpenAI)

```bash
export OPENAI_API_KEY="sk-..."
./target/release/bizclaw chat
```

### Run (with Ollama local model)

```bash
# Start Ollama first
ollama serve &
ollama pull llama3.2

# Run BizClaw with Ollama
./target/release/bizclaw chat --provider ollama --model llama3.2
```

### Run (with Anthropic Claude)

```bash
export ANTHROPIC_API_KEY="sk-ant-..."
./target/release/bizclaw chat --provider anthropic --model claude-sonnet-4-20250514
```

---

## âš™ï¸ Configuration

BizClaw uses TOML configuration at `~/.bizclaw/config.toml`:

```toml
# Default provider
default_provider = "openai"
default_model = "gpt-4o-mini"
default_temperature = 0.7

# Identity
[identity]
name = "BizClaw"
persona = "A helpful AI assistant"
system_prompt = "You are BizClaw, a fast and capable AI assistant."

# Memory
[memory]
backend = "sqlite"  # "sqlite" | "none"
auto_save = true

# Gateway
[gateway]
enabled = false
host = "127.0.0.1"
port = 3000

# Security
[autonomy]
level = "supervised"  # "full" | "supervised" | "locked"
allowed_commands = ["ls", "cat", "echo", "pwd", "find", "grep"]
forbidden_paths = ["/etc", "/var", "~/.ssh"]
```

---

## ğŸ§  Brain Engine (Local Inference)

BizClaw includes a **pure Rust** local inference engine for running GGUF models:

| Component | Description |
|-----------|-------------|
| **GGUF v3 Parser** | Full metadata + tensor index parsing |
| **mmap Loader** | Zero-copy model loading (critical for Pi 512MB) |
| **BPE Tokenizer** | Byte-level encoding with iterative merges |
| **Tensor Ops** | RMSNorm, MatMul, Softmax, SiLU |
| **Quantization** | Q4_0, Q8_0 dequantization kernels |
| **Attention** | Scaled dot-product with multi-head support |
| **KV Cache** | Per-layer key-value cache for generation |
| **RoPE** | Rotary Position Embeddings |
| **Sampler** | Temperature, Top-K, Top-P, repeat penalty |
| **Thread Pool** | Rayon-based parallel matmul |

---

## ğŸ“¡ Gateway API

When enabled, the HTTP gateway exposes:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/v1/info` | GET | System info + uptime |
| `/api/v1/config` | GET | Sanitized config |
| `/api/v1/providers` | GET | Available providers |
| `/api/v1/channels` | GET | Available channels |

---

## ğŸ”’ Security Model

| Feature | Description |
|---------|-------------|
| **Command Allowlist** | Only whitelisted commands can be executed |
| **Path Restrictions** | Forbidden paths (e.g., `~/.ssh`) are rejected |
| **Workspace Only** | Optionally restrict to current working directory |
| **Sandbox** | Timeout, output truncation, restricted env |
| **Secret Store** | JSON with Unix 0600 permissions |

---

## ğŸ§ª Testing

```bash
# Run all tests
cargo test

# Run brain engine tests
cargo test -p bizclaw-brain

# Run memory tests
cargo test -p bizclaw-memory
```

**Current test coverage: 11 tests passing** (tensor math, vector search, RoPE, parallel matmul)

---

## ğŸ—ºï¸ Roadmap

- [x] **Phase 1** â€” Core infrastructure (traits, config, error handling)
- [x] **Phase 1** â€” All providers (OpenAI, Anthropic, Ollama, LlamaCpp, Custom)
- [x] **Phase 1** â€” CLI channel, memory backends, security, gateway
- [x] **Phase 2** â€” Brain engine foundation (GGUF, tokenizer, tensor, quant, attention)
- [ ] **Phase 2** â€” Brain forward pass (wire weights to inference)
- [ ] **Phase 3** â€” Zalo channel (WebSocket login + messaging)
- [ ] **Phase 4** â€” SIMD acceleration (NEON for ARM, AVX2 for x86)
- [ ] **Phase 5** â€” Gateway WebSocket, streaming responses
- [ ] **Phase 6** â€” Telegram, Discord channels

---

## ğŸ“ Project Structure

```
bizclaw/
â”œâ”€â”€ Cargo.toml                 # Workspace root
â”œâ”€â”€ src/main.rs                # CLI binary
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ bizclaw-core/          # Traits, types, config, errors
â”‚   â”œâ”€â”€ bizclaw-brain/         # Local GGUF inference engine
â”‚   â”‚   â”œâ”€â”€ gguf.rs            # GGUF v3 parser
â”‚   â”‚   â”œâ”€â”€ mmap.rs            # Memory-mapped loader
â”‚   â”‚   â”œâ”€â”€ tokenizer.rs       # BPE tokenizer
â”‚   â”‚   â”œâ”€â”€ tensor.rs          # Math ops (RMSNorm, MatMul, etc.)
â”‚   â”‚   â”œâ”€â”€ quant.rs           # Quantization kernels
â”‚   â”‚   â”œâ”€â”€ attention.rs       # Scaled dot-product attention
â”‚   â”‚   â”œâ”€â”€ kv_cache.rs        # Key-value cache
â”‚   â”‚   â”œâ”€â”€ rope.rs            # Rotary position embeddings
â”‚   â”‚   â”œâ”€â”€ sampler.rs         # Token sampling
â”‚   â”‚   â””â”€â”€ model.rs           # LLaMA model params
â”‚   â”œâ”€â”€ bizclaw-providers/     # LLM provider impls
â”‚   â”‚   â”œâ”€â”€ openai.rs          # OpenAI / OpenRouter
â”‚   â”‚   â”œâ”€â”€ anthropic.rs       # Anthropic Claude
â”‚   â”‚   â”œâ”€â”€ ollama.rs          # Ollama (local/remote)
â”‚   â”‚   â”œâ”€â”€ llamacpp.rs        # llama.cpp server
â”‚   â”‚   â””â”€â”€ custom.rs          # Any OpenAI-compatible
â”‚   â”œâ”€â”€ bizclaw-channels/      # Communication channels
â”‚   â”‚   â”œâ”€â”€ cli.rs             # Interactive terminal
â”‚   â”‚   â””â”€â”€ zalo/              # Zalo Personal + OA
â”‚   â”œâ”€â”€ bizclaw-memory/        # Persistence backends
â”‚   â”‚   â”œâ”€â”€ sqlite.rs          # SQLite storage
â”‚   â”‚   â”œâ”€â”€ vector.rs          # In-memory vector search
â”‚   â”‚   â””â”€â”€ noop.rs            # No-op (disabled)
â”‚   â”œâ”€â”€ bizclaw-tools/         # Tool execution
â”‚   â”œâ”€â”€ bizclaw-security/      # Security policies
â”‚   â”œâ”€â”€ bizclaw-agent/         # Agent orchestration
â”‚   â”œâ”€â”€ bizclaw-gateway/       # HTTP REST API
â”‚   â””â”€â”€ bizclaw-runtime/       # Process adapters
â””â”€â”€ plans/                     # Project plans & specs
```

---

## ğŸ“Š Stats

- **Language:** 100% Rust
- **Crates:** 11 (10 library + 1 binary)
- **Lines of Code:** ~5,200
- **Tests:** 11 passing
- **Dependencies:** tokio, axum, reqwest, serde, rusqlite, rayon, memmap2, half

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

**BizClaw** â€” *Fast AI, everywhere.*
